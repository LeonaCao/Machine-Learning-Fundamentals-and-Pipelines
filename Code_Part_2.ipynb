{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Code_Part 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6dPIfx0lmrK",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 2_Part 2\n",
        "## Author: Lei Cao"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnDesZCj0bYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import arange\n",
        "from pandas import set_option\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from matplotlib import pyplot\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAqF-o17lewn",
        "colab_type": "text"
      },
      "source": [
        "### Q3: Pipelines\n",
        "#### 1. In a new notebook, use the same data pre-processing and prep the data (from Q1)\n",
        "#### 2. But now, use the Pipeline instead of SpotCheck\n",
        "#### 3. From the nine possible models listed in Q2, pick the three that worked the best, and let's explore them in more detail\n",
        "##### 1) Use standard scaling and PCA as pre-processing\n",
        "##### 2) Do hyperparameter tuning like they do in the blog\n",
        "#### 4. Use the best fitting model and architecture to predict the holdout data (re-train on all training data, then apply to holdout model)\n",
        "##### 1) Run accuracy metrics - did your results improve over the previous section? Explain why you think this happened"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbAiOOAa0lCy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "fec4e2d3-1bf0-46d8-84fb-28509b747907"
      },
      "source": [
        "# Read in the dataset\n",
        "df = pd.read_csv('~/500Cities_Data.csv')\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 34)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>StateAbbr</th>\n",
              "      <th>PlaceName</th>\n",
              "      <th>PlaceFIPS</th>\n",
              "      <th>Population2010</th>\n",
              "      <th>ACCESS2_CrudePrev</th>\n",
              "      <th>ARTHRITIS_CrudePrev</th>\n",
              "      <th>BINGE_CrudePrev</th>\n",
              "      <th>BPHIGH_CrudePrev</th>\n",
              "      <th>BPMED_CrudePrev</th>\n",
              "      <th>CANCER_CrudePrev</th>\n",
              "      <th>CASTHMA_CrudePrev</th>\n",
              "      <th>CHD_CrudePrev</th>\n",
              "      <th>CHECKUP_CrudePrev</th>\n",
              "      <th>CHOLSCREEN_CrudePrev</th>\n",
              "      <th>COLON_SCREEN_CrudePrev</th>\n",
              "      <th>COPD_CrudePrev</th>\n",
              "      <th>COREM_CrudePrev</th>\n",
              "      <th>COREW_CrudePrev</th>\n",
              "      <th>CSMOKING_CrudePrev</th>\n",
              "      <th>DENTAL_CrudePrev</th>\n",
              "      <th>DIABETES_CrudePrev</th>\n",
              "      <th>HIGHCHOL_CrudePrev</th>\n",
              "      <th>KIDNEY_CrudePrev</th>\n",
              "      <th>LPA_CrudePrev</th>\n",
              "      <th>MAMMOUSE_CrudePrev</th>\n",
              "      <th>MHLTH_CrudePrev</th>\n",
              "      <th>OBESITY_CrudePrev</th>\n",
              "      <th>PAPTEST_CrudePrev</th>\n",
              "      <th>PHLTH_CrudePrev</th>\n",
              "      <th>SLEEP_CrudePrev</th>\n",
              "      <th>STROKE_CrudePrev</th>\n",
              "      <th>TEETHLOST_CrudePrev</th>\n",
              "      <th>Geolocation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>CA</td>\n",
              "      <td>Folsom</td>\n",
              "      <td>624638</td>\n",
              "      <td>72203</td>\n",
              "      <td>7.5</td>\n",
              "      <td>16.9</td>\n",
              "      <td>21.8</td>\n",
              "      <td>25.7</td>\n",
              "      <td>64.8</td>\n",
              "      <td>5.8</td>\n",
              "      <td>8.6</td>\n",
              "      <td>4.1</td>\n",
              "      <td>64.7</td>\n",
              "      <td>78.1</td>\n",
              "      <td>76.6</td>\n",
              "      <td>4.1</td>\n",
              "      <td>37.1</td>\n",
              "      <td>33.3</td>\n",
              "      <td>12.2</td>\n",
              "      <td>74.7</td>\n",
              "      <td>6.7</td>\n",
              "      <td>29.1</td>\n",
              "      <td>2.1</td>\n",
              "      <td>14.3</td>\n",
              "      <td>80.4</td>\n",
              "      <td>9.9</td>\n",
              "      <td>23.8</td>\n",
              "      <td>84.3</td>\n",
              "      <td>8.9</td>\n",
              "      <td>33.9</td>\n",
              "      <td>1.9</td>\n",
              "      <td>6.8</td>\n",
              "      <td>(38.67504943280, -121.147605753)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>FL</td>\n",
              "      <td>Largo</td>\n",
              "      <td>1239425</td>\n",
              "      <td>77648</td>\n",
              "      <td>19.6</td>\n",
              "      <td>30.6</td>\n",
              "      <td>16.9</td>\n",
              "      <td>36.1</td>\n",
              "      <td>81.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.9</td>\n",
              "      <td>9.8</td>\n",
              "      <td>77.5</td>\n",
              "      <td>80.2</td>\n",
              "      <td>64.6</td>\n",
              "      <td>10.0</td>\n",
              "      <td>33.7</td>\n",
              "      <td>33.2</td>\n",
              "      <td>20.7</td>\n",
              "      <td>58.6</td>\n",
              "      <td>12.1</td>\n",
              "      <td>39.0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>31.0</td>\n",
              "      <td>75.7</td>\n",
              "      <td>13.1</td>\n",
              "      <td>28.3</td>\n",
              "      <td>77.1</td>\n",
              "      <td>15.4</td>\n",
              "      <td>37.7</td>\n",
              "      <td>4.5</td>\n",
              "      <td>18.3</td>\n",
              "      <td>(27.90909077340, -82.7714203383)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>CA</td>\n",
              "      <td>Berkeley</td>\n",
              "      <td>606000</td>\n",
              "      <td>112580</td>\n",
              "      <td>7.7</td>\n",
              "      <td>15.1</td>\n",
              "      <td>19.6</td>\n",
              "      <td>20.9</td>\n",
              "      <td>68.2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>8.8</td>\n",
              "      <td>3.7</td>\n",
              "      <td>64.7</td>\n",
              "      <td>70.0</td>\n",
              "      <td>75.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>38.2</td>\n",
              "      <td>36.6</td>\n",
              "      <td>11.2</td>\n",
              "      <td>70.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>27.1</td>\n",
              "      <td>2.1</td>\n",
              "      <td>14.2</td>\n",
              "      <td>81.5</td>\n",
              "      <td>10.9</td>\n",
              "      <td>18.5</td>\n",
              "      <td>83.2</td>\n",
              "      <td>8.2</td>\n",
              "      <td>32.2</td>\n",
              "      <td>1.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>(37.87256787650, -122.274907975)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>CA</td>\n",
              "      <td>Napa</td>\n",
              "      <td>650258</td>\n",
              "      <td>76915</td>\n",
              "      <td>12.3</td>\n",
              "      <td>20.7</td>\n",
              "      <td>19.2</td>\n",
              "      <td>28.1</td>\n",
              "      <td>70.2</td>\n",
              "      <td>6.5</td>\n",
              "      <td>8.9</td>\n",
              "      <td>5.8</td>\n",
              "      <td>63.8</td>\n",
              "      <td>75.4</td>\n",
              "      <td>69.3</td>\n",
              "      <td>5.9</td>\n",
              "      <td>37.9</td>\n",
              "      <td>30.3</td>\n",
              "      <td>14.5</td>\n",
              "      <td>70.2</td>\n",
              "      <td>8.9</td>\n",
              "      <td>34.1</td>\n",
              "      <td>2.8</td>\n",
              "      <td>19.8</td>\n",
              "      <td>76.7</td>\n",
              "      <td>12.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>83.9</td>\n",
              "      <td>12.0</td>\n",
              "      <td>32.7</td>\n",
              "      <td>2.8</td>\n",
              "      <td>11.2</td>\n",
              "      <td>(38.29804246490, -122.301093331)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>FL</td>\n",
              "      <td>Sunrise</td>\n",
              "      <td>1269700</td>\n",
              "      <td>84439</td>\n",
              "      <td>22.8</td>\n",
              "      <td>22.8</td>\n",
              "      <td>16.3</td>\n",
              "      <td>33.3</td>\n",
              "      <td>76.7</td>\n",
              "      <td>6.5</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>77.7</td>\n",
              "      <td>78.7</td>\n",
              "      <td>59.7</td>\n",
              "      <td>7.0</td>\n",
              "      <td>30.5</td>\n",
              "      <td>26.2</td>\n",
              "      <td>16.5</td>\n",
              "      <td>61.0</td>\n",
              "      <td>12.1</td>\n",
              "      <td>37.1</td>\n",
              "      <td>3.2</td>\n",
              "      <td>29.5</td>\n",
              "      <td>82.5</td>\n",
              "      <td>12.7</td>\n",
              "      <td>28.1</td>\n",
              "      <td>81.3</td>\n",
              "      <td>13.3</td>\n",
              "      <td>38.1</td>\n",
              "      <td>3.7</td>\n",
              "      <td>16.2</td>\n",
              "      <td>(26.15468783030, -80.2998411020)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 StateAbbr  ... TEETHLOST_CrudePrev                       Geolocation\n",
              "0           1        CA  ...                 6.8  (38.67504943280, -121.147605753)\n",
              "1           2        FL  ...                18.3  (27.90909077340, -82.7714203383)\n",
              "2           3        CA  ...                 6.7  (37.87256787650, -122.274907975)\n",
              "3           4        CA  ...                11.2  (38.29804246490, -122.301093331)\n",
              "4           5        FL  ...                16.2  (26.15468783030, -80.2998411020)\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__fSjPGP0lAU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "4b9061ab-3ab5-40e5-95bc-10cedeb6a1ef"
      },
      "source": [
        "# Drop any rows with NA\n",
        "df = df.dropna()\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(453, 34)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>StateAbbr</th>\n",
              "      <th>PlaceName</th>\n",
              "      <th>PlaceFIPS</th>\n",
              "      <th>Population2010</th>\n",
              "      <th>ACCESS2_CrudePrev</th>\n",
              "      <th>ARTHRITIS_CrudePrev</th>\n",
              "      <th>BINGE_CrudePrev</th>\n",
              "      <th>BPHIGH_CrudePrev</th>\n",
              "      <th>BPMED_CrudePrev</th>\n",
              "      <th>CANCER_CrudePrev</th>\n",
              "      <th>CASTHMA_CrudePrev</th>\n",
              "      <th>CHD_CrudePrev</th>\n",
              "      <th>CHECKUP_CrudePrev</th>\n",
              "      <th>CHOLSCREEN_CrudePrev</th>\n",
              "      <th>COLON_SCREEN_CrudePrev</th>\n",
              "      <th>COPD_CrudePrev</th>\n",
              "      <th>COREM_CrudePrev</th>\n",
              "      <th>COREW_CrudePrev</th>\n",
              "      <th>CSMOKING_CrudePrev</th>\n",
              "      <th>DENTAL_CrudePrev</th>\n",
              "      <th>DIABETES_CrudePrev</th>\n",
              "      <th>HIGHCHOL_CrudePrev</th>\n",
              "      <th>KIDNEY_CrudePrev</th>\n",
              "      <th>LPA_CrudePrev</th>\n",
              "      <th>MAMMOUSE_CrudePrev</th>\n",
              "      <th>MHLTH_CrudePrev</th>\n",
              "      <th>OBESITY_CrudePrev</th>\n",
              "      <th>PAPTEST_CrudePrev</th>\n",
              "      <th>PHLTH_CrudePrev</th>\n",
              "      <th>SLEEP_CrudePrev</th>\n",
              "      <th>STROKE_CrudePrev</th>\n",
              "      <th>TEETHLOST_CrudePrev</th>\n",
              "      <th>Geolocation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>CA</td>\n",
              "      <td>Folsom</td>\n",
              "      <td>624638</td>\n",
              "      <td>72203</td>\n",
              "      <td>7.5</td>\n",
              "      <td>16.9</td>\n",
              "      <td>21.8</td>\n",
              "      <td>25.7</td>\n",
              "      <td>64.8</td>\n",
              "      <td>5.8</td>\n",
              "      <td>8.6</td>\n",
              "      <td>4.1</td>\n",
              "      <td>64.7</td>\n",
              "      <td>78.1</td>\n",
              "      <td>76.6</td>\n",
              "      <td>4.1</td>\n",
              "      <td>37.1</td>\n",
              "      <td>33.3</td>\n",
              "      <td>12.2</td>\n",
              "      <td>74.7</td>\n",
              "      <td>6.7</td>\n",
              "      <td>29.1</td>\n",
              "      <td>2.1</td>\n",
              "      <td>14.3</td>\n",
              "      <td>80.4</td>\n",
              "      <td>9.9</td>\n",
              "      <td>23.8</td>\n",
              "      <td>84.3</td>\n",
              "      <td>8.9</td>\n",
              "      <td>33.9</td>\n",
              "      <td>1.9</td>\n",
              "      <td>6.8</td>\n",
              "      <td>(38.67504943280, -121.147605753)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>FL</td>\n",
              "      <td>Largo</td>\n",
              "      <td>1239425</td>\n",
              "      <td>77648</td>\n",
              "      <td>19.6</td>\n",
              "      <td>30.6</td>\n",
              "      <td>16.9</td>\n",
              "      <td>36.1</td>\n",
              "      <td>81.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.9</td>\n",
              "      <td>9.8</td>\n",
              "      <td>77.5</td>\n",
              "      <td>80.2</td>\n",
              "      <td>64.6</td>\n",
              "      <td>10.0</td>\n",
              "      <td>33.7</td>\n",
              "      <td>33.2</td>\n",
              "      <td>20.7</td>\n",
              "      <td>58.6</td>\n",
              "      <td>12.1</td>\n",
              "      <td>39.0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>31.0</td>\n",
              "      <td>75.7</td>\n",
              "      <td>13.1</td>\n",
              "      <td>28.3</td>\n",
              "      <td>77.1</td>\n",
              "      <td>15.4</td>\n",
              "      <td>37.7</td>\n",
              "      <td>4.5</td>\n",
              "      <td>18.3</td>\n",
              "      <td>(27.90909077340, -82.7714203383)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>CA</td>\n",
              "      <td>Berkeley</td>\n",
              "      <td>606000</td>\n",
              "      <td>112580</td>\n",
              "      <td>7.7</td>\n",
              "      <td>15.1</td>\n",
              "      <td>19.6</td>\n",
              "      <td>20.9</td>\n",
              "      <td>68.2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>8.8</td>\n",
              "      <td>3.7</td>\n",
              "      <td>64.7</td>\n",
              "      <td>70.0</td>\n",
              "      <td>75.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>38.2</td>\n",
              "      <td>36.6</td>\n",
              "      <td>11.2</td>\n",
              "      <td>70.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>27.1</td>\n",
              "      <td>2.1</td>\n",
              "      <td>14.2</td>\n",
              "      <td>81.5</td>\n",
              "      <td>10.9</td>\n",
              "      <td>18.5</td>\n",
              "      <td>83.2</td>\n",
              "      <td>8.2</td>\n",
              "      <td>32.2</td>\n",
              "      <td>1.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>(37.87256787650, -122.274907975)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>CA</td>\n",
              "      <td>Napa</td>\n",
              "      <td>650258</td>\n",
              "      <td>76915</td>\n",
              "      <td>12.3</td>\n",
              "      <td>20.7</td>\n",
              "      <td>19.2</td>\n",
              "      <td>28.1</td>\n",
              "      <td>70.2</td>\n",
              "      <td>6.5</td>\n",
              "      <td>8.9</td>\n",
              "      <td>5.8</td>\n",
              "      <td>63.8</td>\n",
              "      <td>75.4</td>\n",
              "      <td>69.3</td>\n",
              "      <td>5.9</td>\n",
              "      <td>37.9</td>\n",
              "      <td>30.3</td>\n",
              "      <td>14.5</td>\n",
              "      <td>70.2</td>\n",
              "      <td>8.9</td>\n",
              "      <td>34.1</td>\n",
              "      <td>2.8</td>\n",
              "      <td>19.8</td>\n",
              "      <td>76.7</td>\n",
              "      <td>12.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>83.9</td>\n",
              "      <td>12.0</td>\n",
              "      <td>32.7</td>\n",
              "      <td>2.8</td>\n",
              "      <td>11.2</td>\n",
              "      <td>(38.29804246490, -122.301093331)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>FL</td>\n",
              "      <td>Sunrise</td>\n",
              "      <td>1269700</td>\n",
              "      <td>84439</td>\n",
              "      <td>22.8</td>\n",
              "      <td>22.8</td>\n",
              "      <td>16.3</td>\n",
              "      <td>33.3</td>\n",
              "      <td>76.7</td>\n",
              "      <td>6.5</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>77.7</td>\n",
              "      <td>78.7</td>\n",
              "      <td>59.7</td>\n",
              "      <td>7.0</td>\n",
              "      <td>30.5</td>\n",
              "      <td>26.2</td>\n",
              "      <td>16.5</td>\n",
              "      <td>61.0</td>\n",
              "      <td>12.1</td>\n",
              "      <td>37.1</td>\n",
              "      <td>3.2</td>\n",
              "      <td>29.5</td>\n",
              "      <td>82.5</td>\n",
              "      <td>12.7</td>\n",
              "      <td>28.1</td>\n",
              "      <td>81.3</td>\n",
              "      <td>13.3</td>\n",
              "      <td>38.1</td>\n",
              "      <td>3.7</td>\n",
              "      <td>16.2</td>\n",
              "      <td>(26.15468783030, -80.2998411020)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 StateAbbr  ... TEETHLOST_CrudePrev                       Geolocation\n",
              "0           1        CA  ...                 6.8  (38.67504943280, -121.147605753)\n",
              "1           2        FL  ...                18.3  (27.90909077340, -82.7714203383)\n",
              "2           3        CA  ...                 6.7  (37.87256787650, -122.274907975)\n",
              "3           4        CA  ...                11.2  (38.29804246490, -122.301093331)\n",
              "4           5        FL  ...                16.2  (26.15468783030, -80.2998411020)\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyKAt-Zm0k9E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "17c1a9b9-9def-47e6-cbdf-017ade113885"
      },
      "source": [
        "# Recode the target variable\n",
        "df['Flag_Population'] = (df['Population2010'] > np.median(df['Population2010'])) * 1\n",
        "print(df.shape)\n",
        "print(df.groupby('Flag_Population').size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(453, 35)\n",
            "Flag_Population\n",
            "0    227\n",
            "1    226\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0O3HsKa0k6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare data\n",
        "array = df.values\n",
        "X = array[:, 5:33]\n",
        "Y = array[:, 34]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSvP-ZcC0k3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X.astype(float)\n",
        "Y = Y.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oReGZotU0k0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split-out validation dataset\n",
        "validation_size = 0.20\n",
        "seed = 123\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size = validation_size, random_state = seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_6cHspn0kwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Based on the results of the nine models from Q2, the LinearDiscriminantAnalysis, LogisticRegression, and ExtraTreesClassifier are three models that work the best\n",
        "\n",
        "# Construct pipelines using standard scaling and PCA\n",
        "## LinearDiscriminantAnalysis()\n",
        "pipe_lda = Pipeline([('scl', StandardScaler()), ('pca', PCA(n_components=2)), ('clf', LinearDiscriminantAnalysis())])\n",
        "\n",
        "## LogisticRegression()\n",
        "pipe_lr = Pipeline([('scl', StandardScaler()), ('pca', PCA(n_components=2)), ('clf', LogisticRegression(max_iter=1000000))])\n",
        "\n",
        "## ExtraTreesClassifier()\n",
        "pipe_et = Pipeline([('scl', StandardScaler()), ('pca', PCA(n_components=2)), ('clf', ExtraTreesClassifier(random_state=seed))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf4sdKyD0ktc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set grid search parameters\n",
        "# Because Linear Discriminant Analysis has no hyperparameters to tune, from now steps are done to solely the Logistic Regression and Extra Trees Classifier models\n",
        "param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "param_range_fl = [1.0, 0.5, 0.1]\n",
        "\n",
        "grid_params_lr = [{'clf__penalty': ['l1', 'l2'], 'clf__C': param_range_fl, 'clf__solver': ['liblinear']}]\n",
        "\n",
        "grid_params_et = [{'clf__criterion': ['gini', 'entropy'], 'clf__min_samples_leaf': param_range, 'clf__max_depth': param_range, 'clf__min_samples_split': param_range[1:]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJPS_5VD0kqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Construct grid searches\n",
        "jobs = -1\n",
        "\n",
        "## LogisticRegression()\n",
        "gs_lr = GridSearchCV(estimator = pipe_lr, param_grid = grid_params_lr, scoring = 'accuracy', cv=10)\n",
        "\n",
        "## ExtraTreesClassifier()\n",
        "gs_et = GridSearchCV(estimator = pipe_et, param_grid = grid_params_et, scoring = 'accuracy', cv = 10, n_jobs = jobs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y4wbIYa0kmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# List of pipelines for ease of iteration\n",
        "grids = [gs_lr, gs_et]\n",
        "\n",
        "# Dictionary of pipelines and classifier types for ease of reference\n",
        "grid_dict = {0: 'Logistic Regression', 1: 'Extra Trees Classifier'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcOv6ZKNylpq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "0df94ec3-6636-4c72-9863-0f239f40d0c2"
      },
      "source": [
        "# Fit the grid search objects\n",
        "print('Performing model optimizations...')\n",
        "best_acc = 0.0\n",
        "best_clf = 0\n",
        "best_gs = ''\n",
        "\n",
        "for idx, gs in enumerate(grids):\n",
        "\tprint('\\nEstimator: %s' % grid_dict[idx])\t\n",
        "\t# Fit grid search\t\n",
        "\tgs.fit(X_train, Y_train)\n",
        "\t# Best params\n",
        "\tprint('Best params: %s' % gs.best_params_)\n",
        "\t# Best training data accuracy\n",
        "\tprint('Best training accuracy: %.3f' % gs.best_score_)\n",
        "\t# Predict on test data with best params\n",
        "\tY_pred = gs.predict(X_validation)\n",
        "\t# Test data accuracy of model with best params\n",
        "\tprint('Test set accuracy score for best params: %.3f ' % accuracy_score(Y_validation, Y_pred))\n",
        "\t# Track best (highest test accuracy) model\n",
        "\tif accuracy_score(Y_validation, Y_pred) > best_acc:\n",
        "\t\tbest_acc = accuracy_score(Y_validation, Y_pred)\n",
        "\t\tbest_gs = gs\n",
        "\t\tbest_clf = idx\n",
        "print('\\nClassifier with best test set accuracy: %s' % grid_dict[best_clf])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing model optimizations...\n",
            "\n",
            "Estimator: Logistic Regression\n",
            "Best params: {'clf__C': 0.1, 'clf__penalty': 'l1', 'clf__solver': 'liblinear'}\n",
            "Best training accuracy: 0.577\n",
            "Test set accuracy score for best params: 0.538 \n",
            "\n",
            "Estimator: Extra Trees Classifier\n",
            "Best params: {'clf__criterion': 'gini', 'clf__max_depth': 3, 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 10}\n",
            "Best training accuracy: 0.608\n",
            "Test set accuracy score for best params: 0.538 \n",
            "\n",
            "Classifier with best test set accuracy: Logistic Regression\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwTanIMzu9kD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "afc9aa02-dd52-4c99-f87c-f28587c5103e"
      },
      "source": [
        "# By comparing the accuracy of the Logistic Regression model, which has best test set accuracy, and that of the Linear Discriminant Analysis, \n",
        "# the Logistic Regression model is the best fitting one\n",
        "\n",
        "# Make predictions on validation dataset\n",
        "Model1 = LogisticRegression()\n",
        "Model1.fit(X_train, Y_train)\n",
        "predictions = Model1.predict(X_validation)\n",
        "print(accuracy_score(Y_validation, predictions))\n",
        "print(confusion_matrix(Y_validation, predictions))\n",
        "print(classification_report(Y_validation, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5714285714285714\n",
            "[[20 24]\n",
            " [15 32]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.45      0.51        44\n",
            "           1       0.57      0.68      0.62        47\n",
            "\n",
            "    accuracy                           0.57        91\n",
            "   macro avg       0.57      0.57      0.56        91\n",
            "weighted avg       0.57      0.57      0.57        91\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNm9x1tDpERu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# As shown in the accuracy metrics below, my result improved over the previous section. Because when performing cross-validation, \n",
        "# there will be a data leakage so GridsearchCV fails to find the best model but just focuses on the cross-validation score. \n",
        "# Therefore, using pipeline can solve this problem through model tuning."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}