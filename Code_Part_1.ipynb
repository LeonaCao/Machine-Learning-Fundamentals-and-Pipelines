{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Code_Part 1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOJgKXSYIswb",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 2\n",
        "## Author: Lei Cao"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QYjdR85HxJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from numpy import arange\n",
        "from pandas import set_option\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from matplotlib import pyplot\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import tree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O54x0byHDdWz",
        "colab_type": "text"
      },
      "source": [
        "### Q1: Intro\n",
        "#### 1. Read in the data\n",
        "#### 2. Set the random seed to '123': Do this all of over your script to ensure reproducibility\n",
        "#### 3. Shuffle the rows in your dataset\n",
        "#### 4. Recode the target variable (overwrite the column) to be binary (If greater than median, give it a '1', otherwise give it a '0')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mF9pFCcHxPF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "aa64a2c7-579b-4c94-9f75-f2c760d455ac"
      },
      "source": [
        "# Read in the dataset\n",
        "df = pd.read_csv('~/500Cities_Data.csv')\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 34)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>StateAbbr</th>\n",
              "      <th>PlaceName</th>\n",
              "      <th>PlaceFIPS</th>\n",
              "      <th>Population2010</th>\n",
              "      <th>ACCESS2_CrudePrev</th>\n",
              "      <th>ARTHRITIS_CrudePrev</th>\n",
              "      <th>BINGE_CrudePrev</th>\n",
              "      <th>BPHIGH_CrudePrev</th>\n",
              "      <th>BPMED_CrudePrev</th>\n",
              "      <th>CANCER_CrudePrev</th>\n",
              "      <th>CASTHMA_CrudePrev</th>\n",
              "      <th>CHD_CrudePrev</th>\n",
              "      <th>CHECKUP_CrudePrev</th>\n",
              "      <th>CHOLSCREEN_CrudePrev</th>\n",
              "      <th>COLON_SCREEN_CrudePrev</th>\n",
              "      <th>COPD_CrudePrev</th>\n",
              "      <th>COREM_CrudePrev</th>\n",
              "      <th>COREW_CrudePrev</th>\n",
              "      <th>CSMOKING_CrudePrev</th>\n",
              "      <th>DENTAL_CrudePrev</th>\n",
              "      <th>DIABETES_CrudePrev</th>\n",
              "      <th>HIGHCHOL_CrudePrev</th>\n",
              "      <th>KIDNEY_CrudePrev</th>\n",
              "      <th>LPA_CrudePrev</th>\n",
              "      <th>MAMMOUSE_CrudePrev</th>\n",
              "      <th>MHLTH_CrudePrev</th>\n",
              "      <th>OBESITY_CrudePrev</th>\n",
              "      <th>PAPTEST_CrudePrev</th>\n",
              "      <th>PHLTH_CrudePrev</th>\n",
              "      <th>SLEEP_CrudePrev</th>\n",
              "      <th>STROKE_CrudePrev</th>\n",
              "      <th>TEETHLOST_CrudePrev</th>\n",
              "      <th>Geolocation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>CA</td>\n",
              "      <td>Folsom</td>\n",
              "      <td>624638</td>\n",
              "      <td>72203</td>\n",
              "      <td>7.5</td>\n",
              "      <td>16.9</td>\n",
              "      <td>21.8</td>\n",
              "      <td>25.7</td>\n",
              "      <td>64.8</td>\n",
              "      <td>5.8</td>\n",
              "      <td>8.6</td>\n",
              "      <td>4.1</td>\n",
              "      <td>64.7</td>\n",
              "      <td>78.1</td>\n",
              "      <td>76.6</td>\n",
              "      <td>4.1</td>\n",
              "      <td>37.1</td>\n",
              "      <td>33.3</td>\n",
              "      <td>12.2</td>\n",
              "      <td>74.7</td>\n",
              "      <td>6.7</td>\n",
              "      <td>29.1</td>\n",
              "      <td>2.1</td>\n",
              "      <td>14.3</td>\n",
              "      <td>80.4</td>\n",
              "      <td>9.9</td>\n",
              "      <td>23.8</td>\n",
              "      <td>84.3</td>\n",
              "      <td>8.9</td>\n",
              "      <td>33.9</td>\n",
              "      <td>1.9</td>\n",
              "      <td>6.8</td>\n",
              "      <td>(38.67504943280, -121.147605753)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>FL</td>\n",
              "      <td>Largo</td>\n",
              "      <td>1239425</td>\n",
              "      <td>77648</td>\n",
              "      <td>19.6</td>\n",
              "      <td>30.6</td>\n",
              "      <td>16.9</td>\n",
              "      <td>36.1</td>\n",
              "      <td>81.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.9</td>\n",
              "      <td>9.8</td>\n",
              "      <td>77.5</td>\n",
              "      <td>80.2</td>\n",
              "      <td>64.6</td>\n",
              "      <td>10.0</td>\n",
              "      <td>33.7</td>\n",
              "      <td>33.2</td>\n",
              "      <td>20.7</td>\n",
              "      <td>58.6</td>\n",
              "      <td>12.1</td>\n",
              "      <td>39.0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>31.0</td>\n",
              "      <td>75.7</td>\n",
              "      <td>13.1</td>\n",
              "      <td>28.3</td>\n",
              "      <td>77.1</td>\n",
              "      <td>15.4</td>\n",
              "      <td>37.7</td>\n",
              "      <td>4.5</td>\n",
              "      <td>18.3</td>\n",
              "      <td>(27.90909077340, -82.7714203383)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>CA</td>\n",
              "      <td>Berkeley</td>\n",
              "      <td>606000</td>\n",
              "      <td>112580</td>\n",
              "      <td>7.7</td>\n",
              "      <td>15.1</td>\n",
              "      <td>19.6</td>\n",
              "      <td>20.9</td>\n",
              "      <td>68.2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>8.8</td>\n",
              "      <td>3.7</td>\n",
              "      <td>64.7</td>\n",
              "      <td>70.0</td>\n",
              "      <td>75.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>38.2</td>\n",
              "      <td>36.6</td>\n",
              "      <td>11.2</td>\n",
              "      <td>70.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>27.1</td>\n",
              "      <td>2.1</td>\n",
              "      <td>14.2</td>\n",
              "      <td>81.5</td>\n",
              "      <td>10.9</td>\n",
              "      <td>18.5</td>\n",
              "      <td>83.2</td>\n",
              "      <td>8.2</td>\n",
              "      <td>32.2</td>\n",
              "      <td>1.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>(37.87256787650, -122.274907975)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>CA</td>\n",
              "      <td>Napa</td>\n",
              "      <td>650258</td>\n",
              "      <td>76915</td>\n",
              "      <td>12.3</td>\n",
              "      <td>20.7</td>\n",
              "      <td>19.2</td>\n",
              "      <td>28.1</td>\n",
              "      <td>70.2</td>\n",
              "      <td>6.5</td>\n",
              "      <td>8.9</td>\n",
              "      <td>5.8</td>\n",
              "      <td>63.8</td>\n",
              "      <td>75.4</td>\n",
              "      <td>69.3</td>\n",
              "      <td>5.9</td>\n",
              "      <td>37.9</td>\n",
              "      <td>30.3</td>\n",
              "      <td>14.5</td>\n",
              "      <td>70.2</td>\n",
              "      <td>8.9</td>\n",
              "      <td>34.1</td>\n",
              "      <td>2.8</td>\n",
              "      <td>19.8</td>\n",
              "      <td>76.7</td>\n",
              "      <td>12.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>83.9</td>\n",
              "      <td>12.0</td>\n",
              "      <td>32.7</td>\n",
              "      <td>2.8</td>\n",
              "      <td>11.2</td>\n",
              "      <td>(38.29804246490, -122.301093331)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>FL</td>\n",
              "      <td>Sunrise</td>\n",
              "      <td>1269700</td>\n",
              "      <td>84439</td>\n",
              "      <td>22.8</td>\n",
              "      <td>22.8</td>\n",
              "      <td>16.3</td>\n",
              "      <td>33.3</td>\n",
              "      <td>76.7</td>\n",
              "      <td>6.5</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>77.7</td>\n",
              "      <td>78.7</td>\n",
              "      <td>59.7</td>\n",
              "      <td>7.0</td>\n",
              "      <td>30.5</td>\n",
              "      <td>26.2</td>\n",
              "      <td>16.5</td>\n",
              "      <td>61.0</td>\n",
              "      <td>12.1</td>\n",
              "      <td>37.1</td>\n",
              "      <td>3.2</td>\n",
              "      <td>29.5</td>\n",
              "      <td>82.5</td>\n",
              "      <td>12.7</td>\n",
              "      <td>28.1</td>\n",
              "      <td>81.3</td>\n",
              "      <td>13.3</td>\n",
              "      <td>38.1</td>\n",
              "      <td>3.7</td>\n",
              "      <td>16.2</td>\n",
              "      <td>(26.15468783030, -80.2998411020)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 StateAbbr  ... TEETHLOST_CrudePrev                       Geolocation\n",
              "0           1        CA  ...                 6.8  (38.67504943280, -121.147605753)\n",
              "1           2        FL  ...                18.3  (27.90909077340, -82.7714203383)\n",
              "2           3        CA  ...                 6.7  (37.87256787650, -122.274907975)\n",
              "3           4        CA  ...                11.2  (38.29804246490, -122.301093331)\n",
              "4           5        FL  ...                16.2  (26.15468783030, -80.2998411020)\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q47ZJPGPUwz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "3b9ec52e-5e64-4416-dc06-759c2d17f59c"
      },
      "source": [
        "# Drop any rows with NA\n",
        "df = df.dropna()\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(453, 34)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>StateAbbr</th>\n",
              "      <th>PlaceName</th>\n",
              "      <th>PlaceFIPS</th>\n",
              "      <th>Population2010</th>\n",
              "      <th>ACCESS2_CrudePrev</th>\n",
              "      <th>ARTHRITIS_CrudePrev</th>\n",
              "      <th>BINGE_CrudePrev</th>\n",
              "      <th>BPHIGH_CrudePrev</th>\n",
              "      <th>BPMED_CrudePrev</th>\n",
              "      <th>CANCER_CrudePrev</th>\n",
              "      <th>CASTHMA_CrudePrev</th>\n",
              "      <th>CHD_CrudePrev</th>\n",
              "      <th>CHECKUP_CrudePrev</th>\n",
              "      <th>CHOLSCREEN_CrudePrev</th>\n",
              "      <th>COLON_SCREEN_CrudePrev</th>\n",
              "      <th>COPD_CrudePrev</th>\n",
              "      <th>COREM_CrudePrev</th>\n",
              "      <th>COREW_CrudePrev</th>\n",
              "      <th>CSMOKING_CrudePrev</th>\n",
              "      <th>DENTAL_CrudePrev</th>\n",
              "      <th>DIABETES_CrudePrev</th>\n",
              "      <th>HIGHCHOL_CrudePrev</th>\n",
              "      <th>KIDNEY_CrudePrev</th>\n",
              "      <th>LPA_CrudePrev</th>\n",
              "      <th>MAMMOUSE_CrudePrev</th>\n",
              "      <th>MHLTH_CrudePrev</th>\n",
              "      <th>OBESITY_CrudePrev</th>\n",
              "      <th>PAPTEST_CrudePrev</th>\n",
              "      <th>PHLTH_CrudePrev</th>\n",
              "      <th>SLEEP_CrudePrev</th>\n",
              "      <th>STROKE_CrudePrev</th>\n",
              "      <th>TEETHLOST_CrudePrev</th>\n",
              "      <th>Geolocation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>CA</td>\n",
              "      <td>Folsom</td>\n",
              "      <td>624638</td>\n",
              "      <td>72203</td>\n",
              "      <td>7.5</td>\n",
              "      <td>16.9</td>\n",
              "      <td>21.8</td>\n",
              "      <td>25.7</td>\n",
              "      <td>64.8</td>\n",
              "      <td>5.8</td>\n",
              "      <td>8.6</td>\n",
              "      <td>4.1</td>\n",
              "      <td>64.7</td>\n",
              "      <td>78.1</td>\n",
              "      <td>76.6</td>\n",
              "      <td>4.1</td>\n",
              "      <td>37.1</td>\n",
              "      <td>33.3</td>\n",
              "      <td>12.2</td>\n",
              "      <td>74.7</td>\n",
              "      <td>6.7</td>\n",
              "      <td>29.1</td>\n",
              "      <td>2.1</td>\n",
              "      <td>14.3</td>\n",
              "      <td>80.4</td>\n",
              "      <td>9.9</td>\n",
              "      <td>23.8</td>\n",
              "      <td>84.3</td>\n",
              "      <td>8.9</td>\n",
              "      <td>33.9</td>\n",
              "      <td>1.9</td>\n",
              "      <td>6.8</td>\n",
              "      <td>(38.67504943280, -121.147605753)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>FL</td>\n",
              "      <td>Largo</td>\n",
              "      <td>1239425</td>\n",
              "      <td>77648</td>\n",
              "      <td>19.6</td>\n",
              "      <td>30.6</td>\n",
              "      <td>16.9</td>\n",
              "      <td>36.1</td>\n",
              "      <td>81.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.9</td>\n",
              "      <td>9.8</td>\n",
              "      <td>77.5</td>\n",
              "      <td>80.2</td>\n",
              "      <td>64.6</td>\n",
              "      <td>10.0</td>\n",
              "      <td>33.7</td>\n",
              "      <td>33.2</td>\n",
              "      <td>20.7</td>\n",
              "      <td>58.6</td>\n",
              "      <td>12.1</td>\n",
              "      <td>39.0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>31.0</td>\n",
              "      <td>75.7</td>\n",
              "      <td>13.1</td>\n",
              "      <td>28.3</td>\n",
              "      <td>77.1</td>\n",
              "      <td>15.4</td>\n",
              "      <td>37.7</td>\n",
              "      <td>4.5</td>\n",
              "      <td>18.3</td>\n",
              "      <td>(27.90909077340, -82.7714203383)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>CA</td>\n",
              "      <td>Berkeley</td>\n",
              "      <td>606000</td>\n",
              "      <td>112580</td>\n",
              "      <td>7.7</td>\n",
              "      <td>15.1</td>\n",
              "      <td>19.6</td>\n",
              "      <td>20.9</td>\n",
              "      <td>68.2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>8.8</td>\n",
              "      <td>3.7</td>\n",
              "      <td>64.7</td>\n",
              "      <td>70.0</td>\n",
              "      <td>75.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>38.2</td>\n",
              "      <td>36.6</td>\n",
              "      <td>11.2</td>\n",
              "      <td>70.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>27.1</td>\n",
              "      <td>2.1</td>\n",
              "      <td>14.2</td>\n",
              "      <td>81.5</td>\n",
              "      <td>10.9</td>\n",
              "      <td>18.5</td>\n",
              "      <td>83.2</td>\n",
              "      <td>8.2</td>\n",
              "      <td>32.2</td>\n",
              "      <td>1.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>(37.87256787650, -122.274907975)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>CA</td>\n",
              "      <td>Napa</td>\n",
              "      <td>650258</td>\n",
              "      <td>76915</td>\n",
              "      <td>12.3</td>\n",
              "      <td>20.7</td>\n",
              "      <td>19.2</td>\n",
              "      <td>28.1</td>\n",
              "      <td>70.2</td>\n",
              "      <td>6.5</td>\n",
              "      <td>8.9</td>\n",
              "      <td>5.8</td>\n",
              "      <td>63.8</td>\n",
              "      <td>75.4</td>\n",
              "      <td>69.3</td>\n",
              "      <td>5.9</td>\n",
              "      <td>37.9</td>\n",
              "      <td>30.3</td>\n",
              "      <td>14.5</td>\n",
              "      <td>70.2</td>\n",
              "      <td>8.9</td>\n",
              "      <td>34.1</td>\n",
              "      <td>2.8</td>\n",
              "      <td>19.8</td>\n",
              "      <td>76.7</td>\n",
              "      <td>12.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>83.9</td>\n",
              "      <td>12.0</td>\n",
              "      <td>32.7</td>\n",
              "      <td>2.8</td>\n",
              "      <td>11.2</td>\n",
              "      <td>(38.29804246490, -122.301093331)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>FL</td>\n",
              "      <td>Sunrise</td>\n",
              "      <td>1269700</td>\n",
              "      <td>84439</td>\n",
              "      <td>22.8</td>\n",
              "      <td>22.8</td>\n",
              "      <td>16.3</td>\n",
              "      <td>33.3</td>\n",
              "      <td>76.7</td>\n",
              "      <td>6.5</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>77.7</td>\n",
              "      <td>78.7</td>\n",
              "      <td>59.7</td>\n",
              "      <td>7.0</td>\n",
              "      <td>30.5</td>\n",
              "      <td>26.2</td>\n",
              "      <td>16.5</td>\n",
              "      <td>61.0</td>\n",
              "      <td>12.1</td>\n",
              "      <td>37.1</td>\n",
              "      <td>3.2</td>\n",
              "      <td>29.5</td>\n",
              "      <td>82.5</td>\n",
              "      <td>12.7</td>\n",
              "      <td>28.1</td>\n",
              "      <td>81.3</td>\n",
              "      <td>13.3</td>\n",
              "      <td>38.1</td>\n",
              "      <td>3.7</td>\n",
              "      <td>16.2</td>\n",
              "      <td>(26.15468783030, -80.2998411020)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 StateAbbr  ... TEETHLOST_CrudePrev                       Geolocation\n",
              "0           1        CA  ...                 6.8  (38.67504943280, -121.147605753)\n",
              "1           2        FL  ...                18.3  (27.90909077340, -82.7714203383)\n",
              "2           3        CA  ...                 6.7  (37.87256787650, -122.274907975)\n",
              "3           4        CA  ...                11.2  (38.29804246490, -122.301093331)\n",
              "4           5        FL  ...                16.2  (26.15468783030, -80.2998411020)\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cIHZsjaEoX3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "539db6fe-b92b-4c34-a316-fe5fb68e8bbf"
      },
      "source": [
        "# Recode the target variable\n",
        "df['Flag_Population'] = (df['Population2010'] > np.median(df['Population2010'])) * 1\n",
        "print(df.shape)\n",
        "print(df.groupby('Flag_Population').size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(453, 35)\n",
            "Flag_Population\n",
            "0    227\n",
            "1    226\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdqEMVb2X8A_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare data\n",
        "array = df.values\n",
        "X = array[:, 5:33]\n",
        "Y = array[:, 34]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUM2uosRwQG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X.astype(float)\n",
        "Y = Y.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmaiZnTjHxdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split-out validation dataset\n",
        "validation_size = 0.20\n",
        "seed = 123\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size = validation_size, random_state = seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lu5SgPSxm_z",
        "colab_type": "text"
      },
      "source": [
        "### Q2: Spot-checking and k-fold cross-validation\n",
        "#### 1. Update the models to use all of these:\n",
        "##### 1) GradientBoostingClassifier()\n",
        "##### 2) DecisionTreeClassifier()\n",
        "##### 3) RandomForestClassifier()\n",
        "##### 4) LinearDiscriminantAnalysis()\n",
        "##### 5) LogisticRegression()\n",
        "##### 6) KNeighborsClassifier()\n",
        "##### 7) GaussianNB()\n",
        "##### 8) ExtraTreesClassifier()\n",
        "##### 9) BaggingClassifier()\n",
        "#### 2. Use a 20-fold cross-validation on the data, which model performs the best?\n",
        "#### 3. For the algorithm that performs the best, run the model on all training data and predict the holdout data. Call this Model1\n",
        "#### 4. Try some hyperparameter tuning on that algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-zg3urnHxjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate Algorithms\n",
        "# Test options and evaluation metric\n",
        "num_folds = 20\n",
        "seed = 123\n",
        "scoring = 'accuracy'\n",
        "\n",
        "# Spot Check Algorithms\n",
        "models = []\n",
        "models.append(('GB', GradientBoostingClassifier(random_state=seed)))\n",
        "models.append(('CART', DecisionTreeClassifier(random_state=seed)))\n",
        "models.append(('RF', RandomForestClassifier(random_state=seed)))\n",
        "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
        "models.append(('LR', LogisticRegression(max_iter=1000000)))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('ET', ExtraTreesClassifier(random_state=seed)))\n",
        "models.append(('BC', BaggingClassifier(random_state=seed)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq1Tew1tHxpb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "94107955-814c-49ca-9681-ce0334845cc2"
      },
      "source": [
        "# Evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "for name, model in models:\n",
        "\tkfold = KFold(n_splits = num_folds, random_state = seed, shuffle=True)\n",
        "\tcv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
        "\tresults.append(cv_results)\n",
        "\tnames.append(name)\n",
        "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "\tprint(msg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GB: 0.591813 (0.136998)\n",
            "CART: 0.572661 (0.126690)\n",
            "RF: 0.601901 (0.131655)\n",
            "LDA: 0.572368 (0.092556)\n",
            "LR: 0.564181 (0.099808)\n",
            "KNN: 0.535819 (0.121036)\n",
            "NB: 0.580409 (0.123323)\n",
            "ET: 0.544006 (0.088271)\n",
            "BC: 0.535819 (0.116878)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI0TTk97BznI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "7064888b-208a-438c-a8be-43f01792bf3c"
      },
      "source": [
        "# Compare Algorithms\n",
        "fig = pyplot.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "pyplot.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "pyplot.show()\n",
        "\n",
        "# According to the results above and the following boxplots, the LinearDiscriminantAnalysis model performs the best"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEVCAYAAADwyx6sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNa-oq5DHxsO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "5640ce0d-1c2e-404a-9ba3-6b6ae2645d20"
      },
      "source": [
        "# Make predictions on validation dataset\n",
        "Model1 = LinearDiscriminantAnalysis()\n",
        "Model1.fit(X_train, Y_train)\n",
        "predictions = Model1.predict(X_validation)\n",
        "print(accuracy_score(Y_validation, predictions))\n",
        "print(confusion_matrix(Y_validation, predictions))\n",
        "print(classification_report(Y_validation, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4945054945054945\n",
            "[[18 26]\n",
            " [20 27]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.41      0.44        44\n",
            "           1       0.51      0.57      0.54        47\n",
            "\n",
            "    accuracy                           0.49        91\n",
            "   macro avg       0.49      0.49      0.49        91\n",
            "weighted avg       0.49      0.49      0.49        91\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqI8I_-aHxvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Since the best model I choose is linear discriminant analysis, it has no hyperparameters to tune"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}